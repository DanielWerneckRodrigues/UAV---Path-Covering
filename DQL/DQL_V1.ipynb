{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a reinforcement learning deep q learning algorithim environment for grid world?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, I can help you with that! Here is a step-by-step guide on how to create a Reinforcement Learning Deep Q-Learning Algorithm Environment for Grid World:\n",
    "\n",
    "Install Required Libraries\n",
    "Before you start building the environment, you need to install the required libraries. In this case, we will be using Python and the following libraries: NumPy, Pygame, and TensorFlow. You can install them using the following commands in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Grid World\n",
    "The first step is to create a Grid World. Grid World is an environment where the agent will move around and learn to take the best action to reach the goal state. Here's how to create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, rows, cols, width):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.width = width\n",
    "        self.grid = np.zeros((rows, cols))\n",
    "        self.agent_pos = (0, 0)\n",
    "        self.goal_pos = (rows-1, cols-1)\n",
    "        self.obstacles = [(1, 2), (2, 2), (3, 2)]\n",
    "\n",
    "    def draw_grid(self, screen):\n",
    "        for i in range(self.rows):\n",
    "            for j in range(self.cols):\n",
    "                rect = pygame.Rect(j*self.width, i*self.width, self.width, self.width)\n",
    "                if self.grid[i][j] == 1:\n",
    "                    pygame.draw.rect(screen, (0, 0, 255), rect)\n",
    "                elif self.grid[i][j] == 2:\n",
    "                    pygame.draw.rect(screen, (255, 0, 0), rect)\n",
    "                else:\n",
    "                    pygame.draw.rect(screen, (255, 255, 255), rect)\n",
    "\n",
    "        pygame.draw.rect(screen, (0, 255, 0), pygame.Rect(self.goal_pos[1]*self.width, self.goal_pos[0]*self.width, self.width, self.width))\n",
    "        pygame.draw.rect(screen, (255, 255, 0), pygame.Rect(self.agent_pos[1]*self.width, self.agent_pos[0]*self.width, self.width, self.width))\n",
    "\n",
    "    def move_agent(self, action):\n",
    "        row, col = self.agent_pos\n",
    "        if action == 0: # up\n",
    "            row -= 1\n",
    "        elif action == 1: # down\n",
    "            row += 1\n",
    "        elif action == 2: # left\n",
    "            col -= 1\n",
    "        elif action == 3: # right\n",
    "            col += 1\n",
    "\n",
    "        # check if agent has reached goal or collided with obstacle\n",
    "        if (row, col) == self.goal_pos:\n",
    "            reward = 1\n",
    "            done = True\n",
    "        elif (row, col) in self.obstacles:\n",
    "            reward = -1\n",
    "            done = False\n",
    "        elif row < 0 or row >= self.rows or col < 0 or col >= self.cols:\n",
    "            reward = -1\n",
    "            done = False\n",
    "        else:\n",
    "            reward = 0\n",
    "            done = False\n",
    "\n",
    "        self.agent_pos = (row, col)\n",
    "\n",
    "        return reward, done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Deep Q-Learning Algorithm\n",
    "The next step is to create a Deep Q-Learning Algorithm. Here's how to create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is the 'screen' paramater in the above code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'screen' parameter in the code refers to the Pygame window surface that will be used to draw the Grid World environment. In Pygame, a 'surface' is an object that represents an image or drawing that can be displayed on the screen. In this case, the 'screen' parameter is a Pygame surface object that will be used to draw the Grid World environment.\n",
    "\n",
    "The 'draw_grid' method of the GridWorld class takes the 'screen' parameter as an input, and uses it to draw rectangles on the Pygame surface to represent the different elements of the Grid World environment, such as the agent, goal, and obstacles. The 'draw_grid' method is called repeatedly during the game loop to update the display on the screen as the agent moves through the environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can you give an exameple of the class 'draw_grid'?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here's an example of how you could call the draw_grid method of the GridWorld class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the game window\n",
    "window_width = 400\n",
    "window_height = 400\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Grid World\")\n",
    "\n",
    "# Set up the grid world environment\n",
    "rows = 5\n",
    "cols = 5\n",
    "cell_width = 80\n",
    "grid_world = GridWorld(rows, cols, cell_width)\n",
    "\n",
    "# Game loop\n",
    "running = True\n",
    "while running:\n",
    "    # Handle events\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    # Move the agent randomly\n",
    "    action = random.randint(0, 3)\n",
    "    reward, done = grid_world.move_agent(action)\n",
    "\n",
    "    # Draw the grid world\n",
    "    grid_world.draw_grid(window)\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Clean up\n",
    "pygame.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to make a grid in pygame\n",
    "\n",
    "https://stackoverflow.com/questions/33963361/how-to-make-a-grid-in-pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK = (0, 0, 0)\n",
    "WHITE = (200, 200, 200)\n",
    "WINDOW_HEIGHT = 400\n",
    "WINDOW_WIDTH = 400\n",
    "\n",
    "\n",
    "def main():\n",
    "    global SCREEN, CLOCK\n",
    "    pygame.init()\n",
    "    SCREEN = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n",
    "    CLOCK = pygame.time.Clock()\n",
    "    SCREEN.fill(BLACK)\n",
    "\n",
    "    while True:\n",
    "        drawGrid()\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "\n",
    "def drawGrid():\n",
    "    blockSize = 20 #Set the size of the grid block\n",
    "    for x in range(0, WINDOW_WIDTH, blockSize):\n",
    "        for y in range(0, WINDOW_HEIGHT, blockSize):\n",
    "            rect = pygame.Rect(x, y, blockSize, blockSize)\n",
    "            pygame.draw.rect(SCREEN, WHITE, rect, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can you create a grid with heatmap using pygame?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can create a grid with a heatmap using Pygame. Here's an example implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "class HeatmapGrid:\n",
    "    def __init__(self, rows, cols, cell_size, color_map):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.cell_size = cell_size\n",
    "        self.color_map = color_map\n",
    "\n",
    "        # Create the grid with initial values of zero\n",
    "        self.grid = [[0 for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "    def set_value(self, row, col, value):\n",
    "        self.grid[row][col] = value\n",
    "\n",
    "    def draw_grid(self, surface):\n",
    "        for row in range(self.rows):\n",
    "            for col in range(self.cols):\n",
    "                # Calculate the position of the cell\n",
    "                x = col * self.cell_size\n",
    "                y = row * self.cell_size\n",
    "\n",
    "                # Determine the color of the cell based on its value\n",
    "                value = self.grid[row][col]\n",
    "                color = self.color_map(value)\n",
    "\n",
    "                # Draw the cell on the surface\n",
    "                pygame.draw.rect(surface, color, (x, y, self.cell_size, self.cell_size))\n",
    "\n",
    "# Define a color map function that maps values to colors\n",
    "def get_color(value):\n",
    "    if value < 0:\n",
    "        return (255, 0, 0)  # Red for negative values\n",
    "    else:\n",
    "        return (0, int(value * 255), 0)  # Green for positive values\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the game window\n",
    "window_width = 400\n",
    "window_height = 400\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Heatmap Grid\")\n",
    "\n",
    "# Set up the heatmap grid\n",
    "rows = 5\n",
    "cols = 5\n",
    "cell_size = 80\n",
    "heatmap_grid = HeatmapGrid(rows, cols, cell_size, get_color)\n",
    "\n",
    "# Set some values in the grid\n",
    "heatmap_grid.set_value(0, 0, -0.5)\n",
    "heatmap_grid.set_value(1, 1, 0.25)\n",
    "heatmap_grid.set_value(2, 3, -0.75)\n",
    "heatmap_grid.set_value(3, 2, 0.5)\n",
    "\n",
    "# Game loop\n",
    "running = True\n",
    "while running:\n",
    "    # Handle events\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    # Draw the heatmap grid\n",
    "    heatmap_grid.draw_grid(window)\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Clean up\n",
    "pygame.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we define a HeatmapGrid class that stores a 2D grid of values and can draw the grid on a Pygame surface. The set_value method can be used to set the value of a cell in the grid, and the color_map parameter determines how values are mapped to colors.\n",
    "\n",
    "We also define a get_color function that maps positive values to green and negative values to red. You can customize the get_color function to create your own color scheme.\n",
    "\n",
    "In the game loop, we create a HeatmapGrid object with 5 rows, 5 columns, and cell size of 80 pixels. We then set some values in the grid using the set_value method. Finally, we repeatedly call the draw_grid method of the HeatmapGrid object to update the display on the game window."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can you create a deep reinforcement learning game in a pygame heatmap grid where the agent has to walk throw all the colors?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, here's an example implementation of a deep reinforcement learning game in a Pygame heatmap grid where the agent has to walk through all the colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the color map\n",
    "def get_color(value):\n",
    "    if value == 0:\n",
    "        return (255, 0, 0)  # Red\n",
    "    elif value == 1:\n",
    "        return (0, 255, 0)  # Green\n",
    "    elif value == 2:\n",
    "        return (0, 0, 255)  # Blue\n",
    "    else:\n",
    "        return (255, 255, 255)  # White\n",
    "\n",
    "# Define the Deep Q-Network (DQN) agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Initialize the Q-Network\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(32, activation='relu', input_shape=(state_size,)),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(action_size, activation='linear')\n",
    "        ])\n",
    "        self.model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state))\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = (reward + 0.99 * np.amax(self.model.predict(next_state)[0]))\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "# Define the game environment\n",
    "class ColorGrid:\n",
    "    def __init__(self, rows, cols, cell_size):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.cell_size = cell_size\n",
    "\n",
    "        # Create the grid with initial values of zero\n",
    "        self.grid = [[0 for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "        # Set some random colors in the grid\n",
    "        self.grid[random.randint(0, rows - 1)][random.randint(0, cols - 1)] = 0\n",
    "        self.grid[random.randint(0, rows - 1)][random.randint(0, cols - 1)] = 1\n",
    "        self.grid[random.randint(0, rows - 1)][random.randint(0, cols - 1)] = 2\n",
    "\n",
    "        # Set the agent's starting position\n",
    "        self.agent_row = random.randint(0, rows - 1)\n",
    "        self.agent_col = random.randint(0, cols - 1)\n",
    "\n",
    "    def move_agent(self, action):\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Move the agent based on the chosen action\n",
    "        if action == 0:  # Move up\n",
    "            if self.agent_row > 0:\n",
    "                self.agent_row -= 1\n",
    "        elif action == 1:  # Move down\n",
    "            if self.agent_row < self.rows - 1:\n",
    "                self.agent_row += 1\n",
    "        elif action == 2:  # Move left\n",
    "            if self.agent_col > 0:\n",
    "                self.agent_col -= 1\n",
    "        elif action == 3:  # Move right\n",
    "            if self.agent_col < self.cols - 1:\n",
    "                self.agent_col += 1\n",
    "\n",
    "        # Check if the agent has reached a colored cell\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can you create a deep reinforcement learning game in a pygame heatmap grid where the agent has to walk throw all the colors? It must use a convolucional neural network to predict using screens of the game"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an example implementation of a deep reinforcement learning game in a Pygame heatmap grid where the agent has to walk through all the colors using a Convolutional Neural Network (CNN) to predict using screens of the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the color map\n",
    "def get_color(value):\n",
    "    if value == 0:\n",
    "        return (255, 0, 0)  # Red\n",
    "    elif value == 1:\n",
    "        return (0, 255, 0)  # Green\n",
    "    elif value == 2:\n",
    "        return (0, 0, 255)  # Blue\n",
    "    else:\n",
    "        return (255, 255, 255)  # White\n",
    "\n",
    "# Define the Deep Q-Network (DQN) agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Initialize the Q-Network\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=state_size),\n",
    "            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(action_size, activation='linear')\n",
    "        ])\n",
    "        self.model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state))\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = (reward + 0.99 * np.amax(self.model.predict(next_state)[0]))\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "# Define the game environment\n",
    "class ColorGrid:\n",
    "    def __init__(self, rows, cols, cell_size):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.cell_size = cell_size\n",
    "\n",
    "        # Create the grid with initial values of zero\n",
    "        self.grid = [[0 for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "        # Set some random colors in the grid\n",
    "        self.grid[random.randint(0, rows - 1)][random.randint(0, cols - 1)] = 0\n",
    "        self.grid[random.randint(0, rows - 1)][random.randint(0, cols - 1)] = 1\n",
    "        self.grid[random.randint(0, rows - 1)][random.randint(0, cols - 1)] = 2\n",
    "\n",
    "        # Set the agent's starting position\n",
    "        self.agent_row = random.randint(0, rows - 1)\n",
    "        self.agent_col = random.randint(0, cols - 1)\n",
    "\n",
    "    def move_agent(self, action):\n",
    "        \"\"\"\n",
    "        Moves the agent based on the chosen action.\n",
    "\n",
    "        Parameters:\n",
    "            action (int): the chosen action (0 = move up, 1 = move down, 2 = move left, 3 = move right).\n",
    "\n",
    "        Returns:\n",
    "            surface (pygame.Surface): the current game state as a heatmap surface.\n",
    "            reward (float): the reward obtained from the current action.\n",
    "            done (bool): True if the episode is over, False otherwise.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Move the agent\n",
    "        if action == 0:  # Move up\n",
    "            if self.agent_row > 0:\n",
    "                self.agent_row -= 1\n",
    "        elif action == 1:  # Move down\n",
    "            if self.agent_row < self.rows - 1:\n",
    "                self.agent_row += 1\n",
    "        elif action == 2:  # Move left\n",
    "            if self.agent_col > 0:\n",
    "                self.agent_col -= 1\n",
    "        elif action == 3:  # Move right\n",
    "            if self.agent_col < self.cols - 1:\n",
    "                self.agent_col += 1\n",
    "\n",
    "        # Check if the agent has reached a colored cell\n",
    "        if self.grid[self.agent_row][self.agent_col] != 0:\n",
    "            color_value = self.grid[self.agent_row][self.agent_col]\n",
    "            self.grid[self.agent_row][self.agent_col] = 0\n",
    "            reward = color_value + 1\n",
    "\n",
    "            # Check if all colors have been collected\n",
    "            if all([all([cell == 0 for cell in row]) for row in self.grid]):\n",
    "                done = True\n",
    "\n",
    "        # Convert the grid to a heatmap surface\n",
    "        surface = pygame.Surface((self.cols * self.cell_size, self.rows * self.cell_size))\n",
    "        for row in range(self.rows):\n",
    "            for col in range(self.cols):\n",
    "                color = get_color(self.grid[row][col])\n",
    "                rect = pygame.Rect(col * self.cell_size, row * self.cell_size, self.cell_size, self.cell_size)\n",
    "                pygame.draw.rect(surface, color, rect)\n",
    "\n",
    "        # Draw the agent on top of the heatmap surface\n",
    "        agent_rect = pygame.Rect(self.agent_col * self.cell_size, self.agent_row * self.cell_size, self.cell_size, self.cell_size)\n",
    "        pygame.draw.rect(surface, (255, 255, 0), agent_rect)\n",
    "\n",
    "        return surface, reward, done\n",
    "\n",
    "# Initialize the Pygame environment\n",
    "pygame.init()\n",
    "screen_width, screen_height = 640, 480\n",
    "screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "pygame.display.set_caption('Color Grid RL Game')\n",
    "\n",
    "# Define the game parameters\n",
    "ROWS = 8\n",
    "COLS = 8\n",
    "CELL_SIZE = 50\n",
    "NUM_ACTIONS = 4\n",
    "STATE_SIZE = (ROWS, COLS, 3)  # RGB color channels\n",
    "\n",
    "# Initialize the game and the DQN agent\n",
    "color_grid = ColorGrid(ROWS, COLS, CELL_SIZE)\n",
    "agent = DQNAgent(STATE_SIZE, NUM_ACTIONS)\n",
    "\n",
    "# Train the DQN agent using Q-learning\n",
    "epsilon = 1.0\n",
    "for episode in range(1000):\n",
    "    state = np.expand_dims(np.array(pygame.surfarray.array3d(color_grid.move_agent(0)[0])), axis=0)\n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state, epsilon)\n",
    "        next_state, reward, done = color_grid.move_agent(action)\n",
    "        next_state = np.expand_dims(np.array(pygame.surfarray.array3d(next_state)), axis=0)\n",
    "        agent.train(state, action, reward, next_state, done)\n",
    "        score += reward\n",
    "        state = next_state\n",
    "    epsilon = max(0.1, epsilon * 0.99)\n",
    "    print(f'Episode {episode + 1}: Score = {score}')\n",
    "\n",
    "# Play the game with the trained DQN agent\n",
    "epsilon = 0\n",
    "while True:\n",
    "    state = np.expand_dims(np.array(pygame.surfarray.array3d(color_grid.move_agent(0)[0])), axis=0)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state, epsilon)\n",
    "        next_state, reward, done = color_grid.move_agent(action)\n",
    "        next_state = np.expand_dims(np.array(pygame.surfarray.array3d(next_state)), axis=0)\n",
    "        state = next_state\n",
    "        screen.blit(color_grid.move_agent(0)[0], (0, 0))\n",
    "        pygame.display.update()\n",
    "        pygame.time.delay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom environment that receives a matrix and plots a grid that is a heatmap of the presented matrix. Than, it marks a cell of an agent walking throw the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "class CustomEnv:\n",
    "    def __init__(self, matrix, start_pos, end_pos):\n",
    "        self.matrix = matrix\n",
    "        self.grid_size = matrix.shape\n",
    "        self.start_pos = start_pos\n",
    "        self.end_pos = end_pos\n",
    "        self.current_pos = start_pos\n",
    "        self.heatmap = None\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "\n",
    "    def plot_grid(self):\n",
    "        self.heatmap = self.ax.imshow(self.matrix, cmap=cm.Blues)\n",
    "        self.ax.set_xticks(np.arange(self.grid_size[1]))\n",
    "        self.ax.set_yticks(np.arange(self.grid_size[0]))\n",
    "        self.ax.set_xticklabels([])\n",
    "        self.ax.set_yticklabels([])\n",
    "        self.ax.tick_params(length=0)\n",
    "\n",
    "        for i in range(self.grid_size[0]):\n",
    "            for j in range(self.grid_size[1]):\n",
    "                if self.matrix[i][j] == 1:\n",
    "                    self.ax.text(j, i, 'X', ha='center', va='center', color='black')\n",
    "                if self.matrix[i][j] == 2:\n",
    "                    self.ax.text(j, i, 'O', ha='center', va='center', color='black')\n",
    "\n",
    "    def mark_position(self):\n",
    "        self.ax.text(self.current_pos[1], self.current_pos[0], 'A', ha='center', va='center', color='red')\n",
    "\n",
    "    def update_position(self, action):\n",
    "        if action == 0 and self.current_pos[0] > 0:\n",
    "            self.current_pos[0] -= 1\n",
    "        elif action == 1 and self.current_pos[0] < self.grid_size[0] - 1:\n",
    "            self.current_pos[0] += 1\n",
    "        elif action == 2 and self.current_pos[1] > 0:\n",
    "            self.current_pos[1] -= 1\n",
    "        elif action == 3 and self.current_pos[1] < self.grid_size[1] - 1:\n",
    "            self.current_pos[1] += 1\n",
    "\n",
    "    def get_reward(self):\n",
    "        if np.array_equal(self.current_pos, self.end_pos):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_pos = self.start_pos\n",
    "        self.ax.clear()\n",
    "        self.plot_grid()\n",
    "        self.mark_position()\n",
    "        self.fig.canvas.draw()\n",
    "        return np.copy(self.matrix)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.update_position(action)\n",
    "        reward = self.get_reward()\n",
    "        done = (reward == 1)\n",
    "        self.ax.clear()\n",
    "        self.plot_grid()\n",
    "        self.mark_position()\n",
    "        self.fig.canvas.draw()\n",
    "        return np.copy(self.matrix), reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTE TESTE\n",
    "\n",
    "## state = (posição atual, posições percorridas (lista), matriz do jogo (matriz)) -> da no mesmo que trabalhar com imagens\n",
    "\n",
    "# classe estado - recebe matriz do jogo\n",
    "\n",
    "# plota matriz\n",
    "\n",
    "# posicao atual\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3d036f7185a9a4508ab89d4462eb4f87aba0cb28980c1bc5cdba3e00cc095c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
